{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utvEq2MNEdHc"
   },
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "#!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjj6o8nGnH1f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#with open('/content/drive/My Drive/Colab Notebooks/foo.txt', 'w') as f:\n",
    "#  f.write('Hello Google Drive!')\n",
    "#!cat /content/drive/My\\ Drive/Colab\\ Notebooks/foo.txt\n",
    "#drive.flush_and_unmount()\n",
    "#print('All changes made in this colab session should now be visible in Drive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_Lt8g3REXO4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "DEBUG = 1\n",
    "from datetime import datetime, timedelta\n",
    "#import dateparser\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5jRz7agEXO-"
   },
   "outputs": [],
   "source": [
    "def extractQuestionTitle(driver):\n",
    "    try:\n",
    "        question_title = driver.find_element_by_xpath('.//span[contains(@class, \"ui_qtext_rendered_qtext\")]').text\n",
    "    except Exception as e:\n",
    "        question_title = \"error\"\n",
    "    return question_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdQSoB8IEXPE"
   },
   "outputs": [],
   "source": [
    "def extractTopics(driver):\n",
    "    topic_list = []\n",
    "    \n",
    "    try:\n",
    "        topic_area = driver.find_element_by_xpath(\".//div[contains(@class,'QuestionTopicHorizontalList')]\")\n",
    "    except:\n",
    "        topic_list = ['error']\n",
    "        return topic_list\n",
    "    \n",
    "    topic_list = topic_area.text.split('\\n')\n",
    "           \n",
    "    return topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J92MgGrEXPH"
   },
   "outputs": [],
   "source": [
    "def scrollDownPage(driver, speed):\n",
    "    current_scroll_position, new_height= 0, 1\n",
    "    while current_scroll_position <= new_height:\n",
    "        current_scroll_position += speed\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(current_scroll_position))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJW0j4EjEXPL"
   },
   "outputs": [],
   "source": [
    "def extractRespondContent(driver):\n",
    "    try:\n",
    "        respond_content = driver.find_element_by_xpath(\".//div[@class = 'q-text']\").text\n",
    "    except Exception as e:\n",
    "        respond_content = \"error\"\n",
    "        \n",
    "    return respond_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xp0-ZV-KEXPO"
   },
   "outputs": [],
   "source": [
    "def extractRespondViewAndUpvote(driver):\n",
    "    try:\n",
    "        respond_stat = driver.find_element_by_xpath(\".//div[@class = 'q-text qu-mt--small qu-color--gray_light qu-fontSize--small qu-passColorToLinks']\").text\n",
    "        \n",
    "        view_text = respond_stat.split(\" view\")[0]\n",
    "        if \"k\" in view_text:\n",
    "            respond_view = int(float((view_text.split(\"k\"))[0]) * 1000)\n",
    "        elif \"m\" in view_text:\n",
    "            respond_view = int(float((view_text.split(\"m\"))[0]) * 1000000)\n",
    "        else:\n",
    "            respond_view = int(view_text)\n",
    "        \n",
    "        respond_upvote = 0\n",
    "        if \"Upvoter\" in respond_stat:\n",
    "            upvote_text = (respond_stat.split(\"View \")[1]).split(\" \")[0]\n",
    "            if \"k\" in upvote_text:\n",
    "                respond_upvote = int(float((upvote_text.split(\"k\"))[0]) * 1000)\n",
    "            elif \"m\" in upvote_text:\n",
    "                respond_upvote = int(float((upvote_text.split(\"m\"))[0]) * 1000000)\n",
    "            else:\n",
    "                respond_upvote = int(upvote_text)\n",
    "        else:\n",
    "            respond_upvote = 0\n",
    "            \n",
    "    except:\n",
    "        respond_view = 0\n",
    "        respond_upvote = 0\n",
    "        \n",
    "    return respond_view, respond_upvote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Sw52Hh8EXPW"
   },
   "outputs": [],
   "source": [
    "def extractDate(driver):\n",
    "    try:\n",
    "        log = driver.find_element_by_xpath(\".//p[@class = 'log_action_bar']\")\n",
    "        date = log.text.split(\"· \")[1]\n",
    "    except:\n",
    "        date = \"error\"\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ygW8b46EXPc"
   },
   "outputs": [],
   "source": [
    "def extractAuthor(driver):\n",
    "    block_header = driver.find_element_by_xpath (\".//div[@class = 'feed_item_activity']\")\n",
    "    try:\n",
    "        user_name = block_header.find_element_by_xpath(\".//span[@class = 'anon_user']\").text\n",
    "    except Exception:\n",
    "        try:\n",
    "            user_name = block_header.find_element_by_xpath(\".//a[@class = 'user']\").text\n",
    "        except Exception as e:\n",
    "            user_name = \"error\"\n",
    "    \n",
    "    return user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4r733L4IEXPg"
   },
   "outputs": [],
   "source": [
    "def log_stat_extraction(driver, driver2):\n",
    "    # return element\n",
    "    respond_author_list = []\n",
    "    respond_content_list = []\n",
    "    respond_upvote_list = []\n",
    "    respond_view_list = []\n",
    "    respond_date_list = []\n",
    "    respond_count = 0\n",
    "    question_author = ''\n",
    "    question_create_time = ''\n",
    "    \n",
    "    try:\n",
    "        block_list = driver.find_elements_by_xpath(\".//div[@class = 'pagedlist_item']\")\n",
    "    except:\n",
    "        respond_author_list =  [\"error\"]\n",
    "        respond_content_list = [\"error\"]\n",
    "        respond_upvote_list = [\"error\"]\n",
    "        respond_view_list = [\"error\"]\n",
    "        respond_date_list = [\"error\"]\n",
    "        respond_count = 0\n",
    "        question_auther = \"error\"\n",
    "        question_create_time = \"error\"\n",
    "        \n",
    "        return respond_author_list, respond_content_list, respond_upvote_list, respond_view_list, respond_date_list, respond_count, question_auther, question_create_time\n",
    "        \n",
    "    for block in block_list:\n",
    "        block_error = []\n",
    "        \n",
    "        block_header = block.find_element_by_xpath (\".//div[@class = 'feed_item_activity']\").text\n",
    "        \n",
    "        try:\n",
    "            block_revision = block.find_element_by_xpath (\".//div[@class = 'revision']\").text\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        if 'answer has since been deleted' in block_revision:\n",
    "            continue\n",
    "        elif 'deleted' in block_header:\n",
    "            continue\n",
    "        \n",
    "        if 'Answer' in block_header:\n",
    "            # click the answer link\n",
    "            try:\n",
    "                url2 = block.find_element_by_xpath (\".//div[@class = 'feed_item_activity']/a\").get_attribute('href')\n",
    "                driver2.get(str(url2))\n",
    "                respond_count += 1\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "            # extract author name(log page and driver 1)\n",
    "            respond_author = extractAuthor(block)\n",
    "            respond_author_list.append(respond_author)\n",
    "            \n",
    "            # extract content\n",
    "            respond_content = extractRespondContent(driver2)\n",
    "            respond_content_list.append(respond_content)\n",
    "                \n",
    "            # extract views and upvote\n",
    "            respond_view, respond_upvote = extractRespondViewAndUpvote(driver2)\n",
    "            respond_view_list.append(respond_view)\n",
    "            respond_upvote_list.append(respond_upvote)\n",
    "                \n",
    "            # extract date(log page and driver 1)\n",
    "            respond_date = extractDate(block)\n",
    "            respond_date_list.append(respond_date)\n",
    "            \n",
    "        elif 'Question added by' in block_header:\n",
    "            # extract author name\n",
    "            question_author = extractAuthor(block)\n",
    "            \n",
    "            # extract date\n",
    "            question_create_time = extractDate(block)\n",
    "\n",
    "    return respond_author_list, respond_content_list, respond_upvote_list, respond_view_list, respond_date_list, respond_count, question_author, question_create_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THoPw4GrEXPk"
   },
   "outputs": [],
   "source": [
    "def extractNoOfFollowerAndView(driver):\n",
    "    try:\n",
    "        stats = driver.find_elements_by_xpath(\".//div[@class = 'u-flex u-flex-align--center u-padding-vert--xs u-text--gray-light pass_color_to_child_links u-sans-font-main--small']\")\n",
    "        no_of_follower = int((stats[0].text.split(' '))[0])\n",
    "        no_of_view = (stats[1].text.split(' '))[0]\n",
    "    except:\n",
    "        no_of_follower = 0\n",
    "        no_of_view = 0\n",
    "        \n",
    "    return no_of_follower, no_of_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr9Wd0M3EXPn"
   },
   "outputs": [],
   "source": [
    "def extractQuestion(driver, driver2, url):\n",
    "    data = {}\n",
    "    driver.get(url+'/log')\n",
    "    data['question_title'] = extractQuestionTitle(driver)\n",
    "    data['topic_list'] = extractTopics(driver)\n",
    "    \n",
    "    scrollDownPage(driver, speed = 5)\n",
    "    data['name_list'], data['ans_list'], data['upvote_list'], data['view_list'], data['date_list'], data['respond_collected'], data['question_author'], data['create_time'] = log_stat_extraction(driver, driver2)\n",
    "    \n",
    "    data['no_of_follower'], data['no_of_view'] = extractNoOfFollowerAndView(driver)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZaygfFVEXPr"
   },
   "outputs": [],
   "source": [
    "def readTopics():\n",
    "    with open('/content/drive/My Drive/Colab Notebooks/topics.txt') as topics:\n",
    "        topic_array = topics.readlines()\n",
    "    topic_array = [topic.strip(\"\\n\") for topic in topic_array] \n",
    "    print('Topics: ')\n",
    "    print(topic_array)\n",
    "    print()\n",
    "    return topic_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pg6fUeP2EXPv"
   },
   "outputs": [],
   "source": [
    "def readURLs(file):\n",
    "    with open(file) as URLs:\n",
    "        URL_array = URLs.readlines()\n",
    "    URL_array = [URL.strip(\"\\n\") for URL in URL_array]\n",
    "    return URL_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5LVgDajEXP0"
   },
   "outputs": [],
   "source": [
    "def connectChrome():\n",
    "    # instantiate a chrome options object so you can set the size and headless preference\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\") # 浏览器不提供可视化页面\n",
    "    options.add_argument(\"log-level=3\") # suppress console error/warning/info messages when executing\n",
    "    options.add_argument(\"--incognito\") # 隐身模式启动\n",
    "    options.add_argument('--no-sandbox') # 以最高权限运行\n",
    "    options.add_argument('--disable-dev-shm-usage') # overcome limited resource problems\n",
    "    options.add_argument('blink-settings=imagesEnabled=false')  #不加載圖片, 提升速度\n",
    "    #driver = webdriver.Chrome(executable_path='./chromedriver', options=options)\n",
    "    #driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    \n",
    "    # download the chrome driver from https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "    # and put it in the current directory\n",
    "    #chromedriver = \"/home/youcef/Documents/chromedriver\"\n",
    "    #os.environ[\"webdriver.chrome.driver\"] = chromedriver     \n",
    "    browser = webdriver.Chrome('chromedriver', options=options) \n",
    "    #browser.get(\"https://www.quora.com/\")\n",
    "    #time.sleep(2)\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYapPT0bEXP3"
   },
   "outputs": [],
   "source": [
    "def crawlURLByTopic(topic):\n",
    "    file_location = \"/content/drive/My Drive/Colab Notebooks/topics/\" + topic + \"_question_urls.txt\"\n",
    "    try:\n",
    "        with open(file_location) as f:\n",
    "            print(\"URLs of the topic \\\"\" + topic + \"\\\" has been crawled\")\n",
    "    except:\n",
    "        print(\"Start crawling the URLs of the topic \\\"\" + topic + \"\\\"\")\n",
    "        URLCount = 0\n",
    "        driver = connectChrome()\n",
    "        QuoraURL = \"https://www.quora.com/topic/\" + topic + \"/all_questions\"\n",
    "        print(QuoraURL)\n",
    "        \n",
    "        try:\n",
    "            driver.get(QuoraURL)\n",
    "        except Exception as e0:\n",
    "            print(\"exception e0\")\n",
    "            print(\"Error on line {}\".format(sys.exc_info()[-1].tb_lineno), type(e0).__name__, e0)\n",
    "            return False\n",
    "        \n",
    "        # define pause time for browser\n",
    "        SCROLL_PAUSE_TIME = 2\n",
    "        \n",
    "        # get browser source\n",
    "        html_source = driver.page_source\n",
    "        question_count_soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "        #  get total number of questions\n",
    "        question_count_str = question_count_soup.find(\"a\", attrs = {\"class\": \"TopicQuestionsStatsRow\"})\n",
    "        if str(question_count_str) == \"None\":\n",
    "            print(\"Topic does not exist in Quora, so we will skip it.\")\n",
    "            return False\n",
    "        question_count = question_count_str.contents[0].text \n",
    "        if \"k\" in str(question_count):\n",
    "            question_count = str(question_count).replace(\"k\", \"\")\n",
    "            question_count = int(float(question_count) * 1000)\n",
    "        if \"m\" in str(question_count):\n",
    "            question_count = str(question_count).replace(\"m\", \"\")\n",
    "            question_count = int(float(question_count) * 1000000)\n",
    "        print(\"Number of questions for this topic : \"+ str(question_count))\n",
    "        if str(question_count) == \"0\":            \n",
    "            print(\"Topic has 0 question, so we will skip it.\")\n",
    "            return False\n",
    "        \n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        question_set = set()\n",
    "        # infinite while loop, break it when you reach the end of the page or not able to scroll further.\n",
    "        if int(question_count) > 10:\n",
    "            start_time_sd = time.time()\n",
    "            max_time = int(question_count) * 0.25\n",
    "            if int(question_count) > 8000:\n",
    "                max_time = 1800\n",
    "            while True:\n",
    "                i = 0\n",
    "                # try to scroll 5 times in case of slow connection\n",
    "                while True:\n",
    "                    # Scroll down to one page length\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                    # Wait to load page\n",
    "                    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "                    # get page height in pixels\n",
    "                    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    # break this loop when you are able to scroll futher\n",
    "                    if new_height != last_height:\n",
    "                        break\n",
    "                    if i == 1:\n",
    "                        SCROLL_PAUSE_TIME = 5   \n",
    "                    if i == 2:\n",
    "                        if int(question_count) > 500 and int(question_count) < 2000:\n",
    "                            SCROLL_PAUSE_TIME = 8\n",
    "                        elif int(question_count) > 2000:\n",
    "                            SCROLL_PAUSE_TIME = 16    \n",
    "                        elif int(question_count) < 500:\n",
    "                            break\n",
    "                    if i == 3:\n",
    "                        break\n",
    "                    i += 1\n",
    "                SCROLL_PAUSE_TIME = 2    \n",
    "                # not able to scroll further, break the infinite loop\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                total_time = time.time() - start_time_sd\n",
    "                if total_time > max_time:\n",
    "                    print(\"Max time exceeded\")\n",
    "                    break\n",
    "        print('getting ressources ...')\n",
    "        # get html page source\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "        # question_link is the class for questions\n",
    "        question_link = soup.find_all(\"a\", attrs = {\"class\": \"question_link\"}, href = True)\n",
    "\n",
    "        # add questions to a set for uniqueness\n",
    "        for ques in question_link:\n",
    "            question_set.add(ques)\n",
    "            \n",
    "        # write content of set to a file called question_urls.txt\n",
    "        with open(file_location, 'w') as topic_urls:\n",
    "            writer = csv.writer(topic_urls)\n",
    "            for ques in question_set:\n",
    "                link_url = \"http://www.quora.com\" + ques.attrs['href']\n",
    "                writer.writerows([[link_url]])\n",
    "        \n",
    "    return True\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoXMoUXnEXP6"
   },
   "outputs": [],
   "source": [
    "def crawlQuestionByTopic(topic):\n",
    "    start_time = time.time()\n",
    "    topic_url_file = \"/content/drive/My Drive/Colab Notebooks/topics/\" + topic + \"_question_urls.txt\"\n",
    "    print(topic_url_file)\n",
    "    # Open question url file\n",
    "    file_question_urls = open(topic_url_file, mode = 'r')\n",
    "    answerFile = \"/content/drive/My Drive/Colab Notebooks/\" + topic + \"_answers.txt\"\n",
    "\n",
    "    #file_users = open(os.path.join(sys.path[0]+\"users.txt\", mode = 'a'))\n",
    "    current_lines = file_question_urls.readlines()\n",
    "    URLs = readURLs(topic_url_file)\n",
    "    driver = connectChrome()\n",
    "    driver2 = connectChrome()\n",
    "    topic_array = {}\n",
    "    topic_array[\"topic\"] = topic\n",
    "    topic_array[\"no_of_follows\"] = 0\n",
    "    questions = {}\n",
    "    \n",
    "    print(\"no. of URL: \", len(URLs))\n",
    "    print()\n",
    "    i = 1\n",
    "    for URL in URLs:\n",
    "        \n",
    "        if 'unanswered' in URL:\n",
    "            print(i, ': ', URL)\n",
    "            #print('skip unanswered question')\n",
    "            print()\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        print(i, ': ', URL)\n",
    "        i += 1\n",
    "        question_array = extractQuestion(driver, driver2, URL)\n",
    "        questions[str(len(questions))] = question_array\n",
    "        if not i%100:\n",
    "            print(question_array)\n",
    "        print()\n",
    "        topic_array[\"questions\"] = questions\n",
    "        crawledData = json.dumps(topic_array)\n",
    "        with open(answerFile, \"w\") as file_answers:\n",
    "            file_answers.write(crawledData)\n",
    "            file_answers.close()\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKXlDUsrEXP8"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    topics = readTopics()\n",
    "    for topic in topics:\n",
    "        crawled = crawlURLByTopic(topic)\n",
    "        if crawled:\n",
    "            crawlQuestionByTopic(topic)\n",
    "    \n",
    "if __name__ == \"__main__\": main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2YDg4EL7FzV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Quora_Crawler.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "15giwRyjUVnBShBCzO9C4YDk3xiqmfUu9",
     "timestamp": 1588409790885
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
